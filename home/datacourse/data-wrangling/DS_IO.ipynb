{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%logstop` not found (But line magic `%logstop` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%%logstop\n",
    "#%logstart -rtq ~/.logs/DS_IO.py append\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import expectexception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Exporting Data\n",
    "\n",
    "<!-- requirement: data/sample.txt -->\n",
    "<!-- requirement: data/csv_sample.txt -->\n",
    "<!-- requirement: data/bad_csv.csv -->\n",
    "\n",
    "So far we've only dealt with data that we have created within Python. Generating random data is helpful for testing out ideas, but we want to work with real data. Most often that data will be stored in a file, either locally on the computer or online. In this notebook we'll learn how to read and write data to files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python file handles (`open`)\n",
    "\n",
    "In Python we interact with files on disk using the commands `open` and `close`. We've included a file in the `data` folder called `sample.txt`. Let's open it and read its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will failulations!\n",
      "You've read in data from a file.\n",
      "<_io.TextIOWrapper name='./data/sample.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "f = open('./data/sample.txt', 'r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "print(data)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we `open` the file  and assign it to `f`, `read` the data from `f`, and then close `f`. What is `f`? It's called a **file handle**. It's an object that connects Python to the file we `open`. We `read` the data using this connection, and then once we're done with `close` the connection. It's a good habit to `close` a file handle once we're done with it, so usually we will do it automatically using Python's `with` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will failulations!\n",
      "You've read in data from a file.\n",
      "<_io.TextIOWrapper name='./data/sample.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "# f is automatically closed\n",
    "# at the end of the body of the with statement\n",
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.read())\n",
    "\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read individual lines of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will failulations!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This will failulations!\\n', \"You've read in data from a file.\"]\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sample.txt', 'r') as f:\n",
    "    print(type(f.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Nota Bene!*** The great difference between read and readline is that **read** returns a string while **readline** returns a list where each line is a line of the file handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data to files is very similar. The main difference is when we `open` the file, we will use the `'w'` flag instead of `'r'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.I am practicing writing data to disk.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/my_data.txt', 'w') as f:\n",
    "    f.write('This is a new file.')\n",
    "    f.write('I am practicing writing data to disk.')\n",
    "\n",
    "with open('./data/my_data.txt', 'r') as f:\n",
    "    my_data = f.read()\n",
    "\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how often I execute the above cell, the same output gets printed. Opening the file with the `'w'` flag will overwrite the contents of the file. If we want to add to what is already in the file, we have to open the file with the `'a'` flag (`'a'` stands for _append_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a new file.I am practicing writing data to disk.\n",
      "Adding a new line to the file.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/my_data.txt', 'a') as f:\n",
    "    f.write('\\nAdding a new line to the file.')\n",
    "\n",
    "with open('./data/my_data.txt', 'r') as f:\n",
    "    my_data = f.read()\n",
    "\n",
    "print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always need to be careful when writing to disk, because we could overwrite or alter data by accident. It is also easy to encounter errors when working with files, because we might not know ahead of time if the file we're trying to access exists, or we might mix up the `'r'`, `'w'`, and `'a'` flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExceptionExpected",
     "evalue": "This cell did not raise the expected IOError.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExceptionExpected\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d6332757b86f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expect_exception'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IOError'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n# if a file doesn't exist\\n# we can't open it for reading\\n# (but we can open it for writing)\\n\\nwith open('./data/fail.txt', 'r') as f:\\n    f.read()\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/michaelnana/opt/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-126>\u001b[0m in \u001b[0;36mexpect_exception\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/expectexception/excpectexceptionmagic.py\u001b[0m in \u001b[0;36mexpect_exception\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcell_magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpect_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcell_magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/expectexception/excpectexceptionmagic.py\u001b[0m in \u001b[0;36mrun_cell\u001b[0;34m(self, line, cell, exception_required)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexception_required\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExceptionExpected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This cell did not raise the expected %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomTB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_CustomTB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExceptionExpected\u001b[0m: This cell did not raise the expected IOError."
     ]
    }
   ],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "# if a file doesn't exist\n",
    "# we can't open it for reading\n",
    "# (but we can open it for writing)\n",
    "\n",
    "with open('./data/fail.txt', 'r') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "# we can't read a file open for writing\n",
    "\n",
    "with open('./data/fail.txt', 'w') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-11-776a79381859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/sample.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This will fail'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: not writable\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "# and we can't write to a file open for reading\n",
    "\n",
    "with open('./data/sample.txt', 'r') as f:\n",
    "    f.write('This will fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add a **+** after the mode of the file, we might both read and write and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't read a file open for writing\n",
    "\n",
    "with open('./data/fail.txt', 'w+') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/sample.txt', 'r+') as f:\n",
    "    f.write('This will fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we open a file for writing and then reading, by the time we start reading our cursor we have moved this type of operation is very confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we prevent some of these errors? How do we find out what files are on disk?\n",
    "\n",
    "## `os` module\n",
    "\n",
    "Python has a module for navigating the computer's file system called `os`. There are many useful tools in the `os` module, but there are two functions that are most useful for finding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.done',\n",
       " '.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " 'data',\n",
       " 'DS_Basic_DS_Modules.ipynb',\n",
       " 'DS_Classes_and_ORM.ipynb',\n",
       " 'DS_Data_Munging.ipynb',\n",
       " 'DS_Intro_Statistics.ipynb',\n",
       " 'DS_IO.ipynb',\n",
       " 'DS_IO.ipynb - copie',\n",
       " 'DS_Pandas.ipynb',\n",
       " 'DS_SQL.ipynb',\n",
       " 'dw (1).ipynb',\n",
       " 'miniprojects']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# list the contents of the current directory\n",
    "# ('.' refers to the current directory)\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `listdir` is the simpler of the two functions we'll cover. It simply lists the contents of the directory path we specify. When we pass `'.'` as the argument, `listdir` will look in the current directory. It lists all the Jupyter notebooks we're using for the course, as well as the `data` subdirectory. We could find out what's in the `data` subdirectory by looking in `'./data'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'bad_csv.csv',\n",
       " 'csv_sample.txt',\n",
       " 'customers.csv',\n",
       " 'eog_djvu.txt',\n",
       " 'eog_djvu.txt.1',\n",
       " 'eog_djvu.txt.gz',\n",
       " 'eog_djvu_scrambled.txt.gz',\n",
       " 'example_df.json',\n",
       " 'factbook.csv',\n",
       " 'fail.txt',\n",
       " 'library.json',\n",
       " 'my_data.txt',\n",
       " 'orders.csv',\n",
       " 'pd_write.csv',\n",
       " 'PEP_2016_PEPANNRES.csv',\n",
       " 'pickle_example.pkl',\n",
       " 'pickle_example.txt',\n",
       " 'pickle_sample.json',\n",
       " 'products.csv',\n",
       " 'sample.txt',\n",
       " 'sample_array.npy',\n",
       " 'sample_array.txt',\n",
       " 'short_text.txt',\n",
       " 'short_text.txt.gz',\n",
       " 'yelp.json.gz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to find all the files and subdirectories below a directory somewhere on our computer? With `listdir` we only see the files and subdirectories under the particular directory we're looking in. We cannot use `listdir` to automatically search through subdirectories. For this we need to use `walk`, which \"walks\" through all the subdirectories below our chosen directory. We won't cover `walk` in this course, but it's one of the very useful tools (along with the `os.path` sub-module) for working with files in Python, particularly if you are working with many different data files at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michaelnana/WQU/home/datacourse/.DS_Store\n",
      "/Users/michaelnana/WQU/home/datacourse/update_modules.sh\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/.done\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/.DS_Store\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/DS_Basic_DS_Modules.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/DS_Classes_and_ORM.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/DS_Data_Munging.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/DS_Intro_Statistics.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/DS_IO.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/DS_IO.ipynb - copie\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/DS_Pandas.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/DS_SQL.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/dw (1).ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/.ipynb_checkpoints/DS_Basic_DS_Modules-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/.ipynb_checkpoints/DS_Data_Munging-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/.ipynb_checkpoints/DS_Intro_Statistics-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/.ipynb_checkpoints/DS_IO-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/.ipynb_checkpoints/DS_Pandas-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/.ipynb_checkpoints/dw (1)-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/.DS_Store\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/bad_csv.csv\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/csv_sample.txt\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/customers.csv\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/eog_djvu.txt\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/eog_djvu.txt.1\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/eog_djvu.txt.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/eog_djvu_scrambled.txt.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/example_df.json\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/factbook.csv\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/fail.txt\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/library.json\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/my_data.txt\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/orders.csv\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/pd_write.csv\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/PEP_2016_PEPANNRES.csv\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/pickle_example.pkl\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/pickle_example.txt\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/pickle_sample.json\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/products.csv\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/sample.txt\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/sample_array.npy\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/sample_array.txt\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/short_text.txt\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/short_text.txt.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/data/yelp.json.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/dw.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/in.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/pw.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/.ipynb_checkpoints/dw-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/.ipynb_checkpoints/in-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/.ipynb_checkpoints/pw-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/dw-data/201606scripts_sample.csv.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/dw-data/201701scripts_sample.csv.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/dw-data/chem.csv.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/dw-data/practices.csv.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/pw-data/201701scripts_sample.json.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/data-wrangling/miniprojects/pw-data/practices.json.gz\n",
      "/Users/michaelnana/WQU/home/datacourse/python/.done\n",
      "/Users/michaelnana/WQU/home/datacourse/python/PY_Algorithms.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/PY_DataStructures.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/PY_Intro.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/PY_OOP.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/PY_ProgramFlow.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/PY_Pythonic.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/.ipynb_checkpoints/PY_Algorithms-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/.ipynb_checkpoints/PY_DataStructures-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/.ipynb_checkpoints/PY_Intro-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/.ipynb_checkpoints/PY_OOP-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/.ipynb_checkpoints/PY_ProgramFlow-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/.ipynb_checkpoints/PY_Pythonic-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/images/hash_illustration.png\n",
      "/Users/michaelnana/WQU/home/datacourse/python/images/high_score_flowchart.png\n",
      "/Users/michaelnana/WQU/home/datacourse/python/images/list_illustration.png\n",
      "/Users/michaelnana/WQU/home/datacourse/python/images/nested_logic_flowchart.png\n",
      "/Users/michaelnana/WQU/home/datacourse/python/images/set_operations.png\n",
      "/Users/michaelnana/WQU/home/datacourse/python/miniprojects/in.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/miniprojects/ip.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/miniprojects/vc.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/miniprojects/.ipynb_checkpoints/in-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/miniprojects/.ipynb_checkpoints/ip-checkpoint.ipynb\n",
      "/Users/michaelnana/WQU/home/datacourse/python/miniprojects/.ipynb_checkpoints/vc-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "for directory, _, filenames in os.walk('/Users/michaelnana/WQU/home/datacourse'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(directory, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV files\n",
    "\n",
    "One of the simplest and most common formats for saving data is as comma-separated values (CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index,name,age\n",
      "0,Dylan,28\n",
      "1,Terrence,54\n",
      "2,Mya,31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    csv = f.read()\n",
    "\n",
    "print(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format is often used to represent tables of data. Usually a CSV will have rows (separated by newline characters, `'\\n'`) and columns (separated by commas). Otherwise they are no different from any other text file. We can use the special formatting of a CSV to create a list of lists representing the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'name', 'age'],\n",
       " ['0', 'Dylan', '28'],\n",
       " ['1', 'Terrence', '54'],\n",
       " ['2', 'Mya', '31']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_table = []\n",
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        list_table.append(line.strip().split(','))\n",
    "\n",
    "list_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,Mya,31\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,Mya,31'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn that strip line into a list, we just have to split it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', 'Mya', '31']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'name', 'age'],\n",
       " [0, 'Dylan', 28],\n",
       " [1, 'Terrence', 54],\n",
       " [2, 'Mya', 31]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_line(line):\n",
    "    row = line.strip().split(',')\n",
    "    if row[0]=='index':\n",
    "        return row\n",
    "    return [int(row[0]), row[1], int(row[2])]\n",
    "\n",
    "list_table = []\n",
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        list_table.append(parse_line(line))\n",
    "list_table   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'name', 'age'],\n",
       " row(index=0, name='Dylan', age=28),\n",
       " row(index=1, name='Terrence', age=54),\n",
       " row(index=2, name='Mya', age=31)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Row = namedtuple('row', ['index', 'name', 'age'])\n",
    "\n",
    "def parse_line(line):\n",
    "    row = line.strip().split(',')\n",
    "    if row[0]=='index':\n",
    "        return row\n",
    "    return Row(int(row[0]), row[1], int(row[2]))\n",
    "\n",
    "list_table = []\n",
    "with open('./data/csv_sample.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        list_table.append(parse_line(line))\n",
    "list_table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can work with tabular data much more easily in a Pandas DataFrame. Pandas provides a `read_csv` method to read the data directly into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Terrence</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mya</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  age\n",
       "index               \n",
       "0         Dylan   28\n",
       "1      Terrence   54\n",
       "2           Mya   31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/csv_sample.txt', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_csv` method is very flexible to deal with the formatting of different data sets. Some data sets will include column headers while others may not. Some data sets will include an index while others may not. Some data sets may have values separated by tabs, semicolons, or other characters instead of commas. There are options in the `read_csv` method for dealing with all of these. You can read about them in the [Pandas documentation on `read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html). We'll also discuss it further in the [Pandas notebook](DS_Pandas.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Area(sq km)</th>\n",
       "      <th>Birth rate(births/1000 population)</th>\n",
       "      <th>Current account balance</th>\n",
       "      <th>Death rate(deaths/1000 population)</th>\n",
       "      <th>Debt - external</th>\n",
       "      <th>Electricity - consumption(kWh)</th>\n",
       "      <th>Electricity - production(kWh)</th>\n",
       "      <th>Exports</th>\n",
       "      <th>GDP</th>\n",
       "      <th>...</th>\n",
       "      <th>Oil - production(bbl/day)</th>\n",
       "      <th>Oil - proved reserves(bbl)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Public debt(% of GDP)</th>\n",
       "      <th>Railways(km)</th>\n",
       "      <th>Reserves of foreign exchange &amp; gold</th>\n",
       "      <th>Telephones - main lines in use</th>\n",
       "      <th>Telephones - mobile cellular</th>\n",
       "      <th>Total fertility rate(children born/woman)</th>\n",
       "      <th>Unemployment rate(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>647500</td>\n",
       "      <td>47.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.75</td>\n",
       "      <td>8.000000e+09</td>\n",
       "      <td>6.522000e+08</td>\n",
       "      <td>5.400000e+08</td>\n",
       "      <td>4.460000e+08</td>\n",
       "      <td>2.150000e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>29928987.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33100.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Akrotiri</td>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Albania</td>\n",
       "      <td>28748</td>\n",
       "      <td>15.08</td>\n",
       "      <td>-5.040000e+08</td>\n",
       "      <td>5.12</td>\n",
       "      <td>1.410000e+09</td>\n",
       "      <td>6.760000e+09</td>\n",
       "      <td>5.680000e+09</td>\n",
       "      <td>5.524000e+08</td>\n",
       "      <td>1.746000e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.855000e+08</td>\n",
       "      <td>3563112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1.206000e+09</td>\n",
       "      <td>255000.0</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>2381740</td>\n",
       "      <td>17.13</td>\n",
       "      <td>1.190000e+10</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.190000e+10</td>\n",
       "      <td>2.361000e+10</td>\n",
       "      <td>2.576000e+10</td>\n",
       "      <td>3.216000e+10</td>\n",
       "      <td>2.123000e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1.187000e+10</td>\n",
       "      <td>32531853.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>3973.0</td>\n",
       "      <td>4.355000e+10</td>\n",
       "      <td>2199600.0</td>\n",
       "      <td>1447310.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>199</td>\n",
       "      <td>23.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.209000e+08</td>\n",
       "      <td>1.300000e+08</td>\n",
       "      <td>3.000000e+07</td>\n",
       "      <td>5.000000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57881.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country  Area(sq km)  Birth rate(births/1000 population)  \\\n",
       "0     Afghanistan       647500                               47.02   \n",
       "1        Akrotiri          123                                 NaN   \n",
       "2         Albania        28748                               15.08   \n",
       "3         Algeria      2381740                               17.13   \n",
       "4  American Samoa          199                               23.13   \n",
       "\n",
       "   Current account balance  Death rate(deaths/1000 population)  \\\n",
       "0                      NaN                               20.75   \n",
       "1                      NaN                                 NaN   \n",
       "2            -5.040000e+08                                5.12   \n",
       "3             1.190000e+10                                4.60   \n",
       "4                      NaN                                3.33   \n",
       "\n",
       "   Debt - external  Electricity - consumption(kWh)  \\\n",
       "0     8.000000e+09                    6.522000e+08   \n",
       "1              NaN                             NaN   \n",
       "2     1.410000e+09                    6.760000e+09   \n",
       "3     2.190000e+10                    2.361000e+10   \n",
       "4              NaN                    1.209000e+08   \n",
       "\n",
       "   Electricity - production(kWh)       Exports           GDP  ...  \\\n",
       "0                   5.400000e+08  4.460000e+08  2.150000e+10  ...   \n",
       "1                            NaN           NaN           NaN  ...   \n",
       "2                   5.680000e+09  5.524000e+08  1.746000e+10  ...   \n",
       "3                   2.576000e+10  3.216000e+10  2.123000e+11  ...   \n",
       "4                   1.300000e+08  3.000000e+07  5.000000e+08  ...   \n",
       "\n",
       "   Oil - production(bbl/day)  Oil - proved reserves(bbl)  Population  \\\n",
       "0                        0.0                0.000000e+00  29928987.0   \n",
       "1                        NaN                         NaN         NaN   \n",
       "2                     2000.0                1.855000e+08   3563112.0   \n",
       "3                  1200000.0                1.187000e+10  32531853.0   \n",
       "4                        0.0                         NaN     57881.0   \n",
       "\n",
       "   Public debt(% of GDP)  Railways(km)  Reserves of foreign exchange & gold  \\\n",
       "0                    NaN           NaN                                  NaN   \n",
       "1                    NaN           NaN                                  NaN   \n",
       "2                    NaN         447.0                         1.206000e+09   \n",
       "3                   37.4        3973.0                         4.355000e+10   \n",
       "4                    NaN           NaN                                  NaN   \n",
       "\n",
       "   Telephones - main lines in use  Telephones - mobile cellular  \\\n",
       "0                         33100.0                       15000.0   \n",
       "1                             NaN                           NaN   \n",
       "2                        255000.0                     1100000.0   \n",
       "3                       2199600.0                     1447310.0   \n",
       "4                         15000.0                        2377.0   \n",
       "\n",
       "   Total fertility rate(children born/woman)  Unemployment rate(%)  \n",
       "0                                       6.75                   NaN  \n",
       "1                                        NaN                   NaN  \n",
       "2                                       2.04                  14.8  \n",
       "3                                       1.92                  25.4  \n",
       "4                                       3.25                   6.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of downloading\n",
    "# and importing real data using `read_csv`\n",
    "\n",
    "if 'factbook.csv' not in os.listdir('./data/'):\n",
    "    !wget -P ./data/ https://perso.telecom-paristech.fr/eagan/class/igr204/data/factbook.csv\n",
    "\n",
    "countries = pd.read_csv('./data/factbook.csv', delimiter=';', skiprows=[1])\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a      b\n",
       "0   0   True\n",
       "1   3   True\n",
       "2  10  False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also use pandas to write CSV\n",
    "# using the DataFrame's to_csv method\n",
    "\n",
    "pd.DataFrame({'a': [0, 3, 10], 'b': [True, True, False]}).to_csv('./data/pd_write.csv')\n",
    "\n",
    "pd.read_csv('./data/pd_write.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a CSV won't be perfect. For example, maybe different rows have different numbers of commas. This makes it difficult to interpret the contents of the file as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index,name,age\r\n",
      "0,Dylan,27\r\n",
      "1,54\r\n",
      "2,Mya,31"
     ]
    }
   ],
   "source": [
    "# the 3rd line only has 2 \"columns\"\n",
    "\n",
    "!cat ./data/bad_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mya</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name   age\n",
       "index             \n",
       "0      Dylan  27.0\n",
       "1         54   NaN\n",
       "2        Mya  31.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what happens if we try to read this\n",
    "# into a DataFrame using read_csv?\n",
    "\n",
    "pd.read_csv('./data/bad_csv.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' `read_csv` method will do its best to construct a table out of a poorly formatted CSV, but it may make mistakes. For example, 54 was interpreted as a name instead of as an age, because there were only 2 columns in that line of the file. Data sets will often contain mistakes like bad formatting, missing data, or typos.\n",
    "\n",
    "**Question:** How could we fix the badly formatted CSV so it would work with `read_csv`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mya</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name   age\n",
       "index             \n",
       "0      Dylan  27.0\n",
       "1         54   NaN\n",
       "2        Mya  31.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.read_csv('./data/bad_csv.csv',index_col = 0,error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "JSON stands for JavaScript Object Notation. JavaScript is a common language for creating web applications, and JSON files are used to collect and transmit information between JavaScript applications. As a result, a lot of data on the internet exists in the JSON file format. For example, Twitter and Google Maps use JSON.\n",
    "\n",
    "A JSON file is essentially a data structure built out of nested dictionaries and lists. Let's make our own example and then we'll examine an example downloaded from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book1 = {'title': 'The Prophet',\n",
    "         'author': 'Khalil Gibran',\n",
    "         'genre': 'poetry',\n",
    "         'tags': ['religion', 'spirituality', 'philosophy', 'Lebanon', 'Arabic', 'Middle East'],\n",
    "         'book_id': '811.19',\n",
    "         'copies': [{'edition_year': 1996,\n",
    "                     'checkouts': 486,\n",
    "                     'borrowed': False},\n",
    "                    {'edition_year': 1996,\n",
    "                     'checkouts': 443,\n",
    "                     'borrowed': False}]\n",
    "         }\n",
    "         \n",
    "book2 = {'title': 'The Little Prince',\n",
    "         'author': 'Antoine de Saint-Exupery',\n",
    "         'genre': 'children',\n",
    "         'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
    "         'id': '843.912',\n",
    "         'copies': [{'edition_year': 1983,\n",
    "                     'checkouts': 634,\n",
    "                     'borrowed': True,\n",
    "                     'due_date': '2017/02/02'},\n",
    "                    {'edition_year': 2015,\n",
    "                     'checkouts': 41,\n",
    "                     'borrowed': False}]\n",
    "         }\n",
    "\n",
    "library = [book1, book2]\n",
    "library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two books in our `library`. Both books have some common properties: a title, an author, an id, and tags. Each book can have several tags, so we store that data as a list. Additionally, there can be multiple copies of each book, and each copy also has some unique information like the year it was printed and how many times it's been checked out. Notice that if a book is checked out, it also has a due date. It's convenient to store the information about the multiple copies as a list of dictionaries within the dictionary about the book, because every copy shares the same title, author, etc.\n",
    "\n",
    "This structure is typical of JSON files. It has the advantage of reducing redundancy of data. We only store the author and title once, even though there are multiple copies of the book. Also, we don't store a due date for copies that aren't checked out.\n",
    "\n",
    "If we were to put this data in a table, we would have to duplicate a lot of information. Also, since only one copy in our library is checked out, we also have a column with a lot of missing data.\n",
    "\n",
    "|index|title|author|id|genre|tags|edition_year|checkouts|borrowed|due_date|\n",
    "|:---:|:---:|:----:|::|:---:|:--:|:----------:|:-------:|:------:|:------:|\n",
    "|0|The Prophet|Khalil Gibran|811.19|poetry|religion, spirituality, philosophy, Lebanon, Arabic, Middle East|1996|486|False|Null|\n",
    "|1|The Prophet|Khalil Gibran|811.19|poetry|religion, spirituality, philosophy, Lebanon, Arabic, Middle East|1996|443|False|Null|\n",
    "|2|The Little Prince|Antoine de Saint-Exupery|843.912|children|fantasy, France, philosophy, illustrated, fable|1983|634|True|2017/02/02|\n",
    "|3|The Little Prince|Antoine de Saint-Exupery|843.912|children|fantasy, France, philosophy, illustrated, fable|2015|41|False|Null|\n",
    "\n",
    "This is very wasteful. Since JSON files are meant to be shared quickly over the internet, it is important that they are small to reduce the amount of resources needed to store and transmit them.\n",
    "\n",
    "We can write our `library` to disk using the `json` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/library.json', 'w') as f:\n",
    "    json.dump(library, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"title\": \"The Prophet\",\r\n",
      "    \"author\": \"Khalil Gibran\",\r\n",
      "    \"genre\": \"poetry\",\r\n",
      "    \"tags\": [\r\n",
      "      \"religion\",\r\n",
      "      \"spirituality\",\r\n",
      "      \"philosophy\",\r\n",
      "      \"Lebanon\",\r\n",
      "      \"Arabic\",\r\n",
      "      \"Middle East\"\r\n",
      "    ],\r\n",
      "    \"book_id\": \"811.19\",\r\n",
      "    \"copies\": [\r\n",
      "      {\r\n",
      "        \"edition_year\": 1996,\r\n",
      "        \"checkouts\": 486,\r\n",
      "        \"borrowed\": false\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"edition_year\": 1996,\r\n",
      "        \"checkouts\": 443,\r\n",
      "        \"borrowed\": false\r\n",
      "      }\r\n",
      "    ]\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"title\": \"The Little Prince\",\r\n",
      "    \"author\": \"Antoine de Saint-Exupery\",\r\n",
      "    \"genre\": \"children\",\r\n",
      "    \"tags\": [\r\n",
      "      \"fantasy\",\r\n",
      "      \"France\",\r\n",
      "      \"philosophy\",\r\n",
      "      \"illustrated\",\r\n",
      "      \"fable\"\r\n",
      "    ],\r\n",
      "    \"id\": \"843.912\",\r\n",
      "    \"copies\": [\r\n",
      "      {\r\n",
      "        \"edition_year\": 1983,\r\n",
      "        \"checkouts\": 634,\r\n",
      "        \"borrowed\": true,\r\n",
      "        \"due_date\": \"2017/02/02\"\r\n",
      "      },\r\n",
      "      {\r\n",
      "        \"edition_year\": 2015,\r\n",
      "        \"checkouts\": 41,\r\n",
      "        \"borrowed\": false\r\n",
      "      }\r\n",
      "    ]\r\n",
      "  }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat ./data/library.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/library.json', 'r') as f:\n",
    "    reloaded_library = json.load(f)\n",
    "\n",
    "reloaded_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_library == library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"title\": \"The Prophet\",\\n    \"author\": \"Khalil Gibran\",\\n    \"genre\": \"poetry\",\\n    \"tags\": [\\n      \"religion\",\\n      \"spirituality\",\\n      \"philosophy\",\\n      \"Lebanon\",\\n      \"Arabic\",\\n      \"Middle East\"\\n    ],\\n    \"book_id\": \"811.19\",\\n    \"copies\": [\\n      {\\n        \"edition_year\": 1996,\\n        \"checkouts\": 486,\\n        \"borrowed\": false\\n      },\\n      {\\n        \"edition_year\": 1996,\\n        \"checkouts\": 443,\\n        \"borrowed\": false\\n      }\\n    ]\\n  },\\n  {\\n    \"title\": \"The Little Prince\",\\n    \"author\": \"Antoine de Saint-Exupery\",\\n    \"genre\": \"children\",\\n    \"tags\": [\\n      \"fantasy\",\\n      \"France\",\\n      \"philosophy\",\\n      \"illustrated\",\\n      \"fable\"\\n    ],\\n    \"id\": \"843.912\",\\n    \"copies\": [\\n      {\\n        \"edition_year\": 1983,\\n        \"checkouts\": 634,\\n        \"borrowed\": true,\\n        \"due_date\": \"2017/02/02\"\\n      },\\n      {\\n        \"edition_year\": 2015,\\n        \"checkouts\": 41,\\n        \"borrowed\": false\\n      }\\n    ]\\n  }\\n]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that if we loaded it in without JSON\n",
    "# the file would be interpreted as plain text\n",
    "\n",
    "with open('./data/library.json', 'r') as f:\n",
    "    library_string = f.read()\n",
    "\n",
    "# this isn't what we want\n",
    "library_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'The Prophet',\n",
       "  'author': 'Khalil Gibran',\n",
       "  'genre': 'poetry',\n",
       "  'tags': ['religion',\n",
       "   'spirituality',\n",
       "   'philosophy',\n",
       "   'Lebanon',\n",
       "   'Arabic',\n",
       "   'Middle East'],\n",
       "  'book_id': '811.19',\n",
       "  'copies': [{'edition_year': 1996, 'checkouts': 486, 'borrowed': False},\n",
       "   {'edition_year': 1996, 'checkouts': 443, 'borrowed': False}]},\n",
       " {'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupery',\n",
       "  'genre': 'children',\n",
       "  'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
       "  'id': '843.912',\n",
       "  'copies': [{'edition_year': 1983,\n",
       "    'checkouts': 634,\n",
       "    'borrowed': True,\n",
       "    'due_date': '2017/02/02'},\n",
       "   {'edition_year': 2015, 'checkouts': 41, 'borrowed': False}]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(library_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json.loads(library_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(library_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>tags</th>\n",
       "      <th>book_id</th>\n",
       "      <th>copies</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Prophet</td>\n",
       "      <td>Khalil Gibran</td>\n",
       "      <td>poetry</td>\n",
       "      <td>[religion, spirituality, philosophy, Lebanon, ...</td>\n",
       "      <td>811.19</td>\n",
       "      <td>[{'edition_year': 1996, 'checkouts': 486, 'bor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Little Prince</td>\n",
       "      <td>Antoine de Saint-Exupery</td>\n",
       "      <td>children</td>\n",
       "      <td>[fantasy, France, philosophy, illustrated, fable]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'edition_year': 1983, 'checkouts': 634, 'bor...</td>\n",
       "      <td>843.912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                    author     genre  \\\n",
       "0        The Prophet             Khalil Gibran    poetry   \n",
       "1  The Little Prince  Antoine de Saint-Exupery  children   \n",
       "\n",
       "                                                tags  book_id  \\\n",
       "0  [religion, spirituality, philosophy, Lebanon, ...   811.19   \n",
       "1  [fantasy, France, philosophy, illustrated, fable]      NaN   \n",
       "\n",
       "                                              copies       id  \n",
       "0  [{'edition_year': 1996, 'checkouts': 486, 'bor...      NaN  \n",
       "1  [{'edition_year': 1983, 'checkouts': 634, 'bor...  843.912  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas can also read_json\n",
    "# notice how it constructs the table\n",
    "# does it represent the data well?\n",
    "\n",
    "pd.read_json('./data/library.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":{\"0\":\"Dylan\",\"1\":\"Terrence\",\"2\":\"Mya\"},\"age\":{\"0\":28,\"1\":54,\"2\":31}}"
     ]
    }
   ],
   "source": [
    "# and to_json\n",
    "df.to_json('./data/example_df.json')\n",
    "\n",
    "!head ./data/example_df.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download JSON files many ways. Sometimes we will download it manually, but we can also use `wget` like we did for the CSV example. Often we'll connect to a website's API which will respond using JSON.\n",
    "\n",
    "Panda's `read_json` method is capable of connecting directly to a URL (whether it's the address of a JSON file or an API connection) and reading the JSON without saving the file to our computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>milestone</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>author_association</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>body</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "      <th>pull_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/issues/40732</td>\n",
       "      <td>848532889</td>\n",
       "      <td>MDU6SXNzdWU4NDg1MzI4ODk=</td>\n",
       "      <td>40732</td>\n",
       "      <td>BUG: Dtypes change when using `replace` with n...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-01 14:44:35+00:00</td>\n",
       "      <td>2021-04-01 14:44:35+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- [x] I have checked that this issue has not a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/pull/40731</td>\n",
       "      <td>848528659</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0NjA3NDUzMTY0</td>\n",
       "      <td>40731</td>\n",
       "      <td>ENH: `Styler.to_latex` conversion from CSS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-01 14:39:30+00:00</td>\n",
       "      <td>2021-04-01 14:40:32+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CONTRIBUTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is an extension PR to #40422 (most of thi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/issues/40730</td>\n",
       "      <td>848501764</td>\n",
       "      <td>MDU6SXNzdWU4NDg1MDE3NjQ=</td>\n",
       "      <td>40730</td>\n",
       "      <td>BUG: qcut fails with Float64Dtype</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-01 14:07:16+00:00</td>\n",
       "      <td>2021-04-01 14:18:11+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- [x] I have checked that this issue has not a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/issues/40729</td>\n",
       "      <td>848493310</td>\n",
       "      <td>MDU6SXNzdWU4NDg0OTMzMTA=</td>\n",
       "      <td>40729</td>\n",
       "      <td>BUG: Cannot convert from `object` numeric stri...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-01 13:57:25+00:00</td>\n",
       "      <td>2021-04-01 14:18:40+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- [x] I have checked that this issue has not a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://api.github.com/repos/pandas-dev/pandas...</td>\n",
       "      <td>https://github.com/pandas-dev/pandas/pull/40728</td>\n",
       "      <td>848438676</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0NjA3Mzc3NTE2</td>\n",
       "      <td>40728</td>\n",
       "      <td>REF: only fallback to masked op for object dtype</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-01 12:49:22+00:00</td>\n",
       "      <td>2021-04-01 12:55:29+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>MEMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>While investigating https://github.com/pandas-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/pandas-d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                   repository_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas   \n",
       "\n",
       "                                          labels_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                        comments_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                          events_url  \\\n",
       "0  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "1  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "2  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "3  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "4  https://api.github.com/repos/pandas-dev/pandas...   \n",
       "\n",
       "                                            html_url         id  \\\n",
       "0  https://github.com/pandas-dev/pandas/issues/40732  848532889   \n",
       "1    https://github.com/pandas-dev/pandas/pull/40731  848528659   \n",
       "2  https://github.com/pandas-dev/pandas/issues/40730  848501764   \n",
       "3  https://github.com/pandas-dev/pandas/issues/40729  848493310   \n",
       "4    https://github.com/pandas-dev/pandas/pull/40728  848438676   \n",
       "\n",
       "                            node_id  number  \\\n",
       "0          MDU6SXNzdWU4NDg1MzI4ODk=   40732   \n",
       "1  MDExOlB1bGxSZXF1ZXN0NjA3NDUzMTY0   40731   \n",
       "2          MDU6SXNzdWU4NDg1MDE3NjQ=   40730   \n",
       "3          MDU6SXNzdWU4NDg0OTMzMTA=   40729   \n",
       "4  MDExOlB1bGxSZXF1ZXN0NjA3Mzc3NTE2   40728   \n",
       "\n",
       "                                               title  ... milestone comments  \\\n",
       "0  BUG: Dtypes change when using `replace` with n...  ...       NaN        0   \n",
       "1         ENH: `Styler.to_latex` conversion from CSS  ...       NaN        0   \n",
       "2                  BUG: qcut fails with Float64Dtype  ...       NaN        0   \n",
       "3  BUG: Cannot convert from `object` numeric stri...  ...       NaN        0   \n",
       "4   REF: only fallback to masked op for object dtype  ...       NaN        0   \n",
       "\n",
       "                 created_at                updated_at  closed_at  \\\n",
       "0 2021-04-01 14:44:35+00:00 2021-04-01 14:44:35+00:00        NaT   \n",
       "1 2021-04-01 14:39:30+00:00 2021-04-01 14:40:32+00:00        NaT   \n",
       "2 2021-04-01 14:07:16+00:00 2021-04-01 14:18:11+00:00        NaT   \n",
       "3 2021-04-01 13:57:25+00:00 2021-04-01 14:18:40+00:00        NaT   \n",
       "4 2021-04-01 12:49:22+00:00 2021-04-01 12:55:29+00:00        NaT   \n",
       "\n",
       "  author_association  active_lock_reason  \\\n",
       "0               NONE                 NaN   \n",
       "1        CONTRIBUTOR                 NaN   \n",
       "2               NONE                 NaN   \n",
       "3               NONE                 NaN   \n",
       "4             MEMBER                 NaN   \n",
       "\n",
       "                                                body performed_via_github_app  \\\n",
       "0  - [x] I have checked that this issue has not a...                      NaN   \n",
       "1  This is an extension PR to #40422 (most of thi...                      NaN   \n",
       "2  - [x] I have checked that this issue has not a...                      NaN   \n",
       "3  - [x] I have checked that this issue has not a...                      NaN   \n",
       "4  While investigating https://github.com/pandas-...                      NaN   \n",
       "\n",
       "                                        pull_request  \n",
       "0                                                NaN  \n",
       "1  {'url': 'https://api.github.com/repos/pandas-d...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  {'url': 'https://api.github.com/repos/pandas-d...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('https://api.github.com/repos/pydata/pandas/issues?per_page=5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed files (Gzip)\n",
    "\n",
    "Another way we save storage and network resources is by using **compression**. Many times data sets will contain patterns that can be used to reduce the amount of space needed to store the information.\n",
    "\n",
    "A simple example is the following list of numbers: 10, 10, 10, 2, 3, 3, 3, 3, 3, 50, 50, 1, 1, 50, 10, 10, 10, 10\n",
    "\n",
    "Rather than writing out the full list of numbers (18 integers), we can represent the same information with only 14 numbers: (3, 10), (1, 2), (5, 3), (2, 50), (2, 1), (1, 50), (4, 10)\n",
    "\n",
    "Here the first number in each pair is the number of repetitions, and the second number in the pair is the actual value. We've successfully reduced the amount of numbers we need to represent the same data. Most forms of compression use a similar idea, although actual implementations are usually more complex.\n",
    "\n",
    "In the world of data science, the most common compression is Gzip (which uses the [deflate algorithm](http://www.infinitepartitions.com/art001.html)). Gzip files end with the extension `.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-01 15:45:44--  https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt\n",
      "Résolution de archive.org (archive.org)… 207.241.224.2\n",
      "Connexion à archive.org (archive.org)|207.241.224.2|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : non indiqué [text/html]\n",
      "Sauvegarde en : « ./data/eog_djvu.txt.2 »\n",
      "\n",
      "eog_djvu.txt.2          [    <=>             ] 201.60K   252KB/s    ds 0.8s    \n",
      "\n",
      "2021-04-01 15:45:46 (252 KB/s) - « ./data/eog_djvu.txt.2 » sauvegardé [206443]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./data/ https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 michaelnana  staff   201K Mar  4 14:34 ./data/eog_djvu.txt\r\n",
      "-rw-r--r--  1 michaelnana  staff   202K Apr  1 13:32 ./data/eog_djvu.txt.1\r\n",
      "-rw-r--r--  1 michaelnana  staff   202K Apr  1 15:45 ./data/eog_djvu.txt.2\r\n",
      "-rw-r--r--  1 michaelnana  staff    59K Apr  1 15:45 ./data/eog_djvu.txt.gz\r\n",
      "-rw-r--r--  1 michaelnana  staff   190K Apr  1 13:41 ./data/eog_djvu_scrambled.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "with open('./data/eog_djvu.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "with gzip.open('./data/eog_djvu.txt.gz', 'wb') as f:\n",
    "    f.write(text.encode('utf-8'))\n",
    "\n",
    "!ls -lh ./data/eog*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to compress the text of The Epic of Gilgamesh to a third of its original size! Remember that compression depends on patterns in the data. Language has a lot of patterns, but what would happen if we scrambled all the letters in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 michaelnana  staff   201K Mar  4 14:34 ./data/eog_djvu.txt\r\n",
      "-rw-r--r--  1 michaelnana  staff   202K Apr  1 13:32 ./data/eog_djvu.txt.1\r\n",
      "-rw-r--r--  1 michaelnana  staff   202K Apr  1 15:45 ./data/eog_djvu.txt.2\r\n",
      "-rw-r--r--  1 michaelnana  staff    59K Apr  1 15:45 ./data/eog_djvu.txt.gz\r\n",
      "-rw-r--r--  1 michaelnana  staff   190K Apr  1 15:45 ./data/eog_djvu_scrambled.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with gzip.open('./data/eog_djvu_scrambled.txt.gz', 'wb') as f:\n",
    "    f.write(np.random.permutation(list(text)))\n",
    "\n",
    "!ls -lh ./data/eog*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scrambled version only compressed to two-thirds the size of the original. Compression won't perform very well on random data. Compression also doesn't work very well on data that is already small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 michaelnana  staff     5B Apr  1 15:46 ./data/short_text.txt\r\n",
      "-rw-r--r--  1 michaelnana  staff    40B Apr  1 15:46 ./data/short_text.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "short_text = 'Hello'\n",
    "\n",
    "with open('./data/short_text.txt', 'w') as f:\n",
    "    f.write(short_text)\n",
    "\n",
    "with gzip.open('./data/short_text.txt.gz', 'wb') as f:\n",
    "    f.write(short_text.encode('utf-8'))\n",
    "\n",
    "!ls -lh ./data/short_text*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compressed file is bigger than the plain text! That's because the compressed file includes a header, which takes up a small amount of extra space. Also, since the text is so short, it's not possible to use patterns to represent the text more efficiently. Therefore we usually save compression for large files.\n",
    "\n",
    "You may have noticed that when we write Gzip files, we have been using a `'wb'` flag instead of a plain `'w'` flag. This is because Gzip is not plain text. When compressing the file we write _binary_ files. The files are not readable as plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001f�\b\b��e`\u0002�short_text.txt\u0000�H���\u0007\u0000����\u0005\u0000\u0000\u0000"
     ]
    }
   ],
   "source": [
    "# we have to uncompress the file\n",
    "# before we can read it\n",
    "\n",
    "!cat ./data/short_text.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should only use `'w'` for plain text files (which includes CSV and JSON). Using `'w'` instead of `'wb'` for Gzip files, or other files which are not plain text (e.g. images), could damage the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization (`pickle`)\n",
    "\n",
    "Often we will want to save our work in Python and come back to it later. However, that work might be a machine learning model or some other complex object in Python. How do we save complex Python objects? Python has a module for this purpose called `pickle`. We can use `pickle` to write a binary file that contains all the information about a Python object. Later we can load that pickle file and reconstruct the object in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_example = ['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-48-a9c72e388869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;31m# we can't save this as text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/pickle_example.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not list\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception TypeError\n",
    "\n",
    "# we can't save this as text\n",
    "with open('./data/pickle_example.txt', 'w') as f:\n",
    "    f.write(pickle_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/pickle_example.json', 'w') as f:\n",
    "    json.dump(pickle_example, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', {'a': 23, 'b': True}, [1, 2, 3], [['dogs', 'cats'], None]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/pickle_example.json', 'r') as f:\n",
    "    pickle_json = json.load(f)\n",
    "pickle_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyClass():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type DummyClass is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-f46b2a655070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/json_dummy.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDummyClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type DummyClass is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('./data/json_dummy.json', 'w') as f:\n",
    "    json.dump(DummyClass(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', {'a': 23, 'b': True}, (1, 2, 3), [['dogs', 'cats'], None]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# we can save it as a pickle\n",
    "with open('./data/pickle_example.pkl', 'wb') as f:\n",
    "    pickle.dump(pickle_example, f)\n",
    "\n",
    "with open('./data/pickle_example.pkl', 'rb') as f:\n",
    "    reloaded_example = pickle.load(f)\n",
    "\n",
    "reloaded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the reloaded example is the same as the original\n",
    "\n",
    "reloaded_example == pickle_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_example == pickle_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle is an important tool for data scientists. Data processing and training machine learning models can take a long time, and it is useful to save checkpoints.\n",
    "\n",
    "Pandas also has `to_pickle` and `read_pickle` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pickle_dummy.pkl', 'wb') as f:\n",
    "    pickle.dump(DummyClass(), f)\n",
    "\n",
    "with open('./data/pickle_dummy.pkl', 'rb') as f:\n",
    "    reconstruct_dummy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DummyClass at 0x1132a8350>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruct_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DummyClass at 0x11395a910>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DummyClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pickle_dummy_class.pkl', 'wb') as f:\n",
    "    pickle.dump(DummyClass, f)\n",
    "\n",
    "with open('./data/pickle_dummy_class.pkl', 'rb') as f:\n",
    "    reconstructed_dummy_class = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.DummyClass"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_dummy_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DummyClass at 0x11395b250>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_dummy_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.DummyClass"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DummyClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy file formats\n",
    "\n",
    "NumPy also has methods for saving and loading data. They are straightforward to use. You may encounter these when working with certain machine learning libraries that require data be stored in NumPy arrays. NumPy arrays are also often used when working with image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66681332 0.49012765 0.55357114 0.30563232]\n",
      " [0.24133966 0.73099853 0.19699266 0.30008158]\n",
      " [0.53466161 0.40905872 0.58042775 0.97517591]\n",
      " [0.83137155 0.06410636 0.2474217  0.15227604]]\n"
     ]
    }
   ],
   "source": [
    "sample_array = np.random.random((4, 4))\n",
    "print(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save as plain text\n",
    "np.savetxt('./data/sample_array.txt', sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.668133201969191903e-01 4.901276532494619476e-01 5.535711426089019449e-01 3.056323230535571422e-01\r\n",
      "2.413396581501711102e-01 7.309985280746658098e-01 1.969926612697755486e-01 3.000815810868574518e-01\r\n",
      "5.346616050674577458e-01 4.090587194164195806e-01 5.804277487297836435e-01 9.751759110548676723e-01\r\n",
      "8.313715519316032809e-01 6.410636430891658577e-02 2.474217014347694921e-01 1.522760429335215937e-01\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./data/sample_array.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66681332 0.49012765 0.55357114 0.30563232]\n",
      " [0.24133966 0.73099853 0.19699266 0.30008158]\n",
      " [0.53466161 0.40905872 0.58042775 0.97517591]\n",
      " [0.83137155 0.06410636 0.2474217  0.15227604]]\n"
     ]
    }
   ],
   "source": [
    "print(np.loadtxt('./data/sample_array.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save as compressed binary\n",
    "np.save('./data/sample_array.npy', sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�NUMPY\u0001\u0000v\u0000{'descr': '<f8', 'fortran_order': False, 'shape': (4, 4), }                                                          \r\n",
      "�\r",
      "Y�V�?2�d`@^�?}w0�ڶ�?�d\u0007�z��?��}�7��?�'p\u0006Wd�?\u001c",
      "T�6\u000e7�?\u0002�9`�4�?�!���\u001b�?�`��\u0004.�?ˇ�6ݒ�?4|�\u001c",
      "�4�??�K����? \u0019,RFi�?P������?�.\b�}�?"
     ]
    }
   ],
   "source": [
    "!cat ./data/sample_array.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66681332 0.49012765 0.55357114 0.30563232]\n",
      " [0.24133966 0.73099853 0.19699266 0.30008158]\n",
      " [0.53466161 0.40905872 0.58042775 0.97517591]\n",
      " [0.83137155 0.06410636 0.2474217  0.15227604]]\n"
     ]
    }
   ],
   "source": [
    "print(np.load('./data/sample_array.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 michaelnana  staff  256 Apr  1 18:59 ./data/sample_array.npy\r\n",
      "-rw-r--r--  1 michaelnana  staff  400 Apr  1 18:58 ./data/sample_array.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./data/sample_array.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics used by not discussed:\n",
    "- BASH commands (!)\n",
    "- `wget`\n",
    "- `str.split()`\n",
    "- APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2020 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
